<h1>Direct Demod - Automatic NOAA Map and Globe Projection</h1>
<h2>Combining Maps from Multiple DSGN Stations and Scrolling through Time</h2>

<h3>This project is for adding supplement files for the following <a href="https://docs.google.com/document/d/1dH36BWyLU2bjtMudt8bBVoROjMZty47-XSv6j485FmY/edit?usp=sharing">proposal</a>.</h3>
<h3>Contents</h3>
<p>This project aims to improve the current rendering of map and globe from DirectDemod python libraries, along with combining maps from different 
stations and being able to view data along a large time-zone.</p>

<p>
    The following issues are faced while rendering data from multiple record stations, combining and syncing them, along with rendering them -
    <li><b>Large Data Set</b><br>
        The data set to be represented for this project is very large. Having data from many satellites, and having many captures of data from each
        satellite per day, leads us to the problem of maintaining and handling large data sets.
        We have to cover obtaining data from DSGN stations, and their parallel processing using python script.
    </li>
    <br>
    <li><b>Efficient Data Retrieval</b><br>
        Efficient Data Retrieval from data-bases is also important for faster rendering of data into web-page. 
        We have to design our database schema in such format, that we have both write and retieve operation as fast as possible, i.e. 
        <br>1. when processing data, we can store it efficiently
        <br>2. accesing data for rendering
        <br>
        For this, we will use the concept of de-centralised NoSQL database. The schema is discussed below. 
    </li>
    <br>
    <li><b>Algorithm for merging and syncing of processed data</b><br>
        As we are showing data through time, we will collect the data, over a large range of days, from many satellites.There is a good possibility that
        data from the satellites are captured at differnet timestamps, and we need to devise an algorithm, to sync and merge the data captured at
        different time.
    </li>
    <br>
    <li><b>Merging of Different Data Sets</b><br>
        The merge python code, as worked on during last summer, will need heavy modification, as now we are merging data-sets over an added parameter - time.
        Hence it is suggested that a new merging algorithm is developed from the existing work, to add new parameters.
    </li>
    <br>
    <li><b>Time Scrolling</b><br>
        Discussed as .gif format below.
    </li>
    <br>
    <li><b>Increase Robustness</b><br>
        A new data-format, offset variable is added to help improve the robustness of the webpage, and increase user flexibility.
    </li>
</p>


<h3>Project Details</h3>

<li>
    <b>Obtaining SDR file from DSGN Station and parallely processing data</b><br><br>
    <img src="./images/ParallelProcessing.png" width="60%">
    <br><br>
    This image clarifies the parallel processing of multiple singals from record stations, and storing it in JSON format in **Collection database.
    This is done using **misc.py.
    <br>
</li><br>

<li>
    <b>Algorithm for merging and syncing of processed data</b><br><br>
    For simplicity, we assume we have data from 2 satellites only.
    <br><br>For satellite-1:<br>
    Let us say the first SDR file recieved has data at timestamp 't1'.<br>
    Eg. t=0000hrs<br>
    It will now periodically capture data after every 'X1' time.<br>
    Eg. If X1=30 minutes, we have next snapshots at 0030hrs, 0100hrs, 0130hrs, and so on. 
    
    <br><br>For satellite-2:<br>
    Let us say the first SDR file recieved has data at timestamp 't2'.<br>
    Eg. t=0010hrs<br>
    It will now periodically capture data after every 'X2' time.<br>
    Eg. If X2=30 minutes, we have next snapshots at 0040hrs, 0110hrs, 0140hrs, and so on. 

    <br><br>We can't merge data from satellite-1 at 0000hrs, with 0010hrs, without making any changes.The proposed solution for this is - 
    <br><br>For every fixed time period, let us say T' time, a satellite would generate only 1 image which will show the average representation of
    data over that time period. Multiple and no signals would be implemented during the coding part of the idea.
    <br>
    Eg. T' = 15 minutes.<br>
    Therefore, the map will show data at every 15 minutes, i.e. 0015hrs, 0030hrs, 0045hrs, and so on.
    Here, <br>
    0015hrs - Merging of satellite-1 (0000hrs data), and satellite-2 (0010hrs data)<br>
    0030hrs - Merging of satellite-1 (0030hrs data), and satellite-2 (0010hrs data)<br>
    0045hrs - Merging of satellite-1 (0030hrs data), and satellite-2 (0040hrs data)<br>

    The value of T' would be kept to provide very accurate representation of data, and can be externally configured by user.
    <br>
</li><br>

<li>
    <b>DataBase Schema & Merging of Database</b><br><br>
    For this purpose, we would be using a de-centralised NoSQL database, like MongoDB to efficiently perform the CRUD operations.

    <br>
</li><br>

<li>
    <b>Time Scrolling</b><br><br>
    <img src="./images/WorldMapTimelineScroll.gif" width="60%">
    <br><br>
    For representation purposes, a gif showing the spread of coronavirus in the world map, across a time range is used.
    A feature similar to this would be used for scrolling through the time.

    <br>
</li><br>

<li>
    <b>Offset Parameter - Increasing Robustness and Flexibility</b><br><br>
    A web-widget tool would be prepared (just the front end schema/skeleton portion) which would let users have more control over data from which satellite is to be rendered.

    <br>
</li><br>
